{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some simple commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2.])\n",
    "y = torch.tensor([3., 2.])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "                  [1., 2.], \n",
    "                  [3., 2.], \n",
    "                  [0., 4.],\n",
    "                 ])\n",
    "print(x[0][1])\n",
    "x[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = torch.tensor([3., 2.], device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/mnist/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train.label.values\n",
    "train = train.drop(columns=\"label\").values.reshape(len(train_labels), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape for a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_labels = len(set(train_labels))\n",
    "        img_height = 28\n",
    "        img_width = 28 \n",
    "        s_in = img_height * img_width\n",
    "        s2 = 392\n",
    "        s3 = 196\n",
    "        s4 = 98\n",
    "        s_out = num_labels\n",
    "        \n",
    "        self.fc1 = nn.Linear(s_in, s2) # fully connected\n",
    "        self.fc2 = nn.Linear(s2, s3)\n",
    "        self.fc3 = nn.Linear(s3, s4)\n",
    "        self.fc4 = nn.Linear(s4, s_out)\n",
    "        # regularise NN to avoid overfitting\n",
    "        self.dropout = nn.Dropout(p=0.2) # 20% of nodes will be randomly \n",
    "                                         # not used during training iterations \n",
    "                                         # makes network more robust since each node\n",
    "                                          # will not be used in every iteration.\n",
    "    def forward(self, x):\n",
    "        \"\"\"forward pass\"\"\"\n",
    "        x = x.view(x.shape[0], -1) # flatten img size to one long vector\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier()\n",
    "loss_function = nn.NLLLoss() # negative log likelyhood -> loss = -log(y)\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLLLoss()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTClassifier(\n",
       "  (fc1): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (fc2): Linear(in_features=392, out_features=196, bias=True)\n",
       "  (fc3): Linear(in_features=196, out_features=98, bias=True)\n",
       "  (fc4): Linear(in_features=98, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch requires features to be floats for gradients\n",
    "y = torch.Tensor(train_labels).long() # long -> 64bit integers\n",
    "# enforce labels as integers\n",
    "X = torch.Tensor(train.astype(float)) # 32bit floating-point numbers \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/50 Loss: 0.25746870040893555\n",
      "epoch 1/50 Loss: 0.2520117461681366\n",
      "epoch 2/50 Loss: 0.25036194920539856\n",
      "epoch 3/50 Loss: 0.2453850656747818\n",
      "epoch 4/50 Loss: 0.23968103528022766\n",
      "epoch 5/50 Loss: 0.23763632774353027\n",
      "epoch 6/50 Loss: 0.23409509658813477\n",
      "epoch 7/50 Loss: 0.22732368111610413\n",
      "epoch 8/50 Loss: 0.22185702621936798\n",
      "epoch 9/50 Loss: 0.22170798480510712\n",
      "epoch 10/50 Loss: 0.2187337428331375\n",
      "epoch 11/50 Loss: 0.21716316044330597\n",
      "epoch 12/50 Loss: 0.21428647637367249\n",
      "epoch 13/50 Loss: 0.21122561395168304\n",
      "epoch 14/50 Loss: 0.20733249187469482\n",
      "epoch 15/50 Loss: 0.1997411698102951\n",
      "epoch 16/50 Loss: 0.19777585566043854\n",
      "epoch 17/50 Loss: 0.19691821932792664\n",
      "epoch 18/50 Loss: 0.19304496049880981\n",
      "epoch 19/50 Loss: 0.19227662682533264\n",
      "epoch 20/50 Loss: 0.19132159650325775\n",
      "epoch 21/50 Loss: 0.18614822626113892\n",
      "epoch 22/50 Loss: 0.184334397315979\n",
      "epoch 23/50 Loss: 0.1840767115354538\n",
      "epoch 24/50 Loss: 0.18102434277534485\n",
      "epoch 25/50 Loss: 0.17897947132587433\n",
      "epoch 26/50 Loss: 0.17472636699676514\n",
      "epoch 27/50 Loss: 0.17516541481018066\n",
      "epoch 28/50 Loss: 0.16765636205673218\n",
      "epoch 29/50 Loss: 0.1648421734571457\n",
      "epoch 30/50 Loss: 0.167617529630661\n",
      "epoch 31/50 Loss: 0.1640140265226364\n",
      "epoch 32/50 Loss: 0.15905605256557465\n",
      "epoch 33/50 Loss: 0.1605403870344162\n",
      "epoch 34/50 Loss: 0.15437863767147064\n",
      "epoch 35/50 Loss: 0.157815083861351\n",
      "epoch 36/50 Loss: 0.1520320177078247\n",
      "epoch 37/50 Loss: 0.154206782579422\n",
      "epoch 38/50 Loss: 0.15165865421295166\n",
      "epoch 39/50 Loss: 0.15240825712680817\n",
      "epoch 40/50 Loss: 0.14788927137851715\n",
      "epoch 41/50 Loss: 0.14785899221897125\n",
      "epoch 42/50 Loss: 0.14266186952590942\n",
      "epoch 43/50 Loss: 0.14295004308223724\n",
      "epoch 44/50 Loss: 0.14128945767879486\n",
      "epoch 45/50 Loss: 0.1363462209701538\n",
      "epoch 46/50 Loss: 0.13710227608680725\n",
      "epoch 47/50 Loss: 0.1356654018163681\n",
      "epoch 48/50 Loss: 0.1352706402540207\n",
      "epoch 49/50 Loss: 0.13256901502609253\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    # transform to variable so that they have the \"backward()\" method\n",
    "    images = Variable(X)\n",
    "    labels = Variable(y)\n",
    "    \n",
    "    # set all gradients to zero first\n",
    "    # gradients are calculated cumulatively on each back prop which is useful in RNNs\n",
    "    # but in this case we want the gradient of the epoch only\n",
    "    # so after each pass re-set it to zero\n",
    "    opt.zero_grad() \n",
    "    # make  the forward pass:\n",
    "    outputs = model(images)\n",
    "    # calculate the loss\n",
    "    loss = loss_function(outputs, labels)\n",
    "    # backprop the loss\n",
    "    loss.backward()\n",
    "    # update the model paramates using the optimiser\n",
    "    opt.step()\n",
    "    # print the total loss\n",
    "    print(f\"epoch {epoch}/{epochs} Loss: {loss.data.item()}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
